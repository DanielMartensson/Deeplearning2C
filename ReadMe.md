## What is this project?
This is Deeplearning2C. It's a project for generate an application for Android, Iphone, Linux, Windows and Mac OS X, that can generate a deep neural network in a .c file after being trained with Deeplearning4J.

I have been using the following dependencies

* Deeplearning4J
* GluonHQ JavaFX for Android & Iphone development
* Lombok
* Logback-classic

## Why should I use this application?
Let's say that you want to implement an deep neural network that are trained for classification for animals or other visible things. You want to implement it into a microcontroller such as STM32, PIC, AVR. Then this application can be used to generate a deep neural network in C code.

## What kind neural network can this application generate in C?
This application generate DenseLayer and OutputLayer from DL4J into C-code. 
I will focusing on LSTM layers to, but the problem is that I have no idea how to get all the weight matrices from a LSTM layer.

From this code in TrainEvalGeneratePresenter.java in method generateCCode()
```
Layer layer = dL4JModel.getMultiLayerNetwork().getLayer(i);
Map<String, INDArray> weights = layer.paramTable();
System.out.println(weights.keySet());
```
I get the output [W, b] for a DenseLayer and OutputLayer.
I get the output [W, WR, b] for an LSTM layer. 

I was given this Java class from Skymind engineers. So I assuming that the matrices [W, WR, b] contains several matrices. I just need to find its dimensions and what order they are placed to do the matrix math in C-code. 
https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/recurrent/LSTMHelpers.java

If you can send me a code(open an issue) how to get all weight matrices for a LSTM layer from [W, WR, b]. I will implement C-code generation for LSTM in this application.

## How does it looks like?
Here are some images when I run Deeplearning2C on Linux.

Model selection

![a](https://raw.githubusercontent.com/DanielMartensson/Deeplearning2C/master/pictures/Models.png)

Menu

![a](https://raw.githubusercontent.com/DanielMartensson/Deeplearning2C/master/pictures/Menu.png)

Global configuration

![a](https://raw.githubusercontent.com/DanielMartensson/Deeplearning2C/master/pictures/Global.png)

Layer configuration

![a](https://raw.githubusercontent.com/DanielMartensson/Deeplearning2C/master/pictures/Layer.png)

Training data configuration

![a](https://raw.githubusercontent.com/DanielMartensson/Deeplearning2C/master/pictures/Data.png)

Training the model

![a](https://raw.githubusercontent.com/DanielMartensson/Deeplearning2C/master/pictures/Training.png)


Applied onto a Samsung Galaxy S3 from 2012

![a](https://raw.githubusercontent.com/DanielMartensson/Deeplearning2C/master/pictures/Samsung%20S3.jpeg)

This is how a C-code generation example looks like for a DenseLayer

```
/*
 * Model: MnistNetwork
 *
 *  Created on: 2019/08/30 01:55:35
 *  	Generated by: Deeplearning2C
 *     		Author: Daniel MÃ¥rtensson
 */

#include "MnistNetwork.h"
#include "BLAS/f2c.h"
#include "BLAS/functions.h"

void MnistNetwork(float* input, float* output){

	integer m = 0; // Real row dimension of non-transpose A
	integer n = 0; // Read column dimension of non-transpose A
	real alpha = 1; // Always 1
	real beta = 1; // Always 1
	integer incx = 1; // Always 1
	integer incy = 1; // Always 1
	char trans = 'N'; // We have transpose matrix A'

	/*
	 * We are using BLAS subroutine sgemv for solving y = alpha*A*x + beta*y
	 * The BLAS subroutine is the same routine that is used in EmbeddedLapack
	 * Solve the equations like:
	 * b0 = act(W0*input + b0)
	 * b1 = act(W1*b0 + b1)
	 * b2 = act(W2*b1 + b2)
	 * b3 = act(W3*b2 + b3)
	 * b4 = act(W4*b3 + b4)
	 * ....
	 * ....
	 * output = act(Wi*b(i-1) + bi)
	 */

	real b0[1*3]={    0.0232,    0.1241,   -0.2364};
	real W0[4*3]={   -0.0941,    0.5298,    0.1350, 
			  0.4098,   -0.1581,   -0.2768, 
			  0.1868,   -0.0455,   -0.4475, 
			  0.6364,   -0.0308,    0.0176};
	m = 3;
	n = 4;
	sgemv_(&trans, &m, &n, &alpha, W0, &m, input, &incx, &beta, b0, &incy); // Layer - first - index 0
	activation(b0, m, "TANH");

	real b1[1*5]={    0.4525,    0.3542,    0.5536,    0.5452,    0.0341};
	real W1[3*5]={    0.4700,    0.0400,   -0.5242,    0.2811,   -0.3237, 
			  0.4370,    0.1803,   -0.2792,   -0.9658,   -0.0308, 
			  0.6427,    0.5957,   -0.1436,    0.4655,    0.0814};
	m = 5;
	n = 3;
	sgemv_(&trans, &m, &n, &alpha, W1, &m, b0, &incx, &beta, b1, &incy); // Layer - middle - index 1
	activation(b1, m, "RELU");

	real b2[1*7]={    0.0342,    0.0354,    0.4321,    0.4361,    0.2562,    0.5432,    0.3422};
	real W2[5*7]={   -0.2502,    0.0784,    0.3791,    0.2962,    0.2535,   -0.5057,    0.9582, 
			 -0.2891,   -0.2954,    0.6359,   -0.3486,    0.0073,    0.8808,   -0.4316, 
			  0.0807,   -0.3676,   -0.0770,   -0.2822,    0.4525,    0.3630,    0.9813, 
			  0.0789,    0.2669,    0.8258,    0.1127,   -0.1861,   -0.3904,   -0.0130, 
			  0.5324,   -0.0029,    0.1769,    0.0877,   -0.2769,   -0.3287,    0.0768};
	m = 7;
	n = 5;
	sgemv_(&trans, &m, &n, &alpha, W2, &m, b1, &incx, &beta, b2, &incy); // Layer - middle - index 2
	activation(b2, m, "RELU");

	real b3[1*3]={    0.0234,    0.0001,    0.0245};
	real W3[7*3]={    0.1710,    0.4176,   -0.8350, 
			 -1.0480,   -0.3556,   -0.5316, 
			 -1.0776,   -0.5987,    0.1679, 
			 -0.9875,   -0.6696,   -0.3076, 
			  0.4895,    0.1993,    0.2712, 
			  0.8676,    0.1215,   -0.0029, 
			 -0.1123,   -0.2475,    0.7278};
	m = 3;
	n = 7;
	sgemv_(&trans, &m, &n, &alpha, W3, &m, b2, &incx, &beta, output, &incy); // Layer - last - index 3
	activation(output, m, "SOFTMAX");

}

```

## I like this project! How can I get the installation file?

First of all. The installation file is over 600 megabytes. That's huge, but anyway it's still possible to install. You need to have OpenJDK 8 and OpenJFX 8 installed. If you are an Ubuntu user, then follow these steps:

1. Install OpenJDK 8

```
sudo apt-get install openjdk-8-jdk
```

2. Install OpenJFX 8
```
Open sources.list file 

cd /etc/apt
sudo nano sources.list

Paste this into the file and save and close

deb http://de.archive.ubuntu.com/ubuntu/ bionic universe

Run these code inside the terminal

sudo apt-get update
sudo apt install openjfx=8u161-b12-1ubuntu2 libopenjfx-java=8u161-b12-1ubuntu2 libopenjfx-jni=8u161-b12-1ubuntu2 openjfx-source=8u161-b12-1ubuntu2
sudo apt-mark hold libopenjfx-java libopenjfx-jni openjfx openjfx-source
```

3. Install Eclipse 2018-09 (4.9.0) R (Because Eclipse 2018-09 will only work with Gluon Plugin 2.6.0)
```
  https://www.eclipse.org/downloads/packages/release/2018-09/r
```

4. Install Gluon Plugin 2.6.0 inside Eclipse
```
  Help -> Eclipse Marketplace -> Gluon 2.6.0
```

Now you can download my Deeplearning2C project and import that project into your Eclipse IDE.  Have fun and generate the .jar file for Win,Lin,Mac. 

5. (Optional) See the getting started guide for using GluonHQ JavaFX for mobile development. It's a very easy and excellent done graphical manual. It describes how to set up the Android SDK etc. https://docs.gluonhq.com/getting-started/#introduction

6. (Optional) Troubleshooting for Android can be done this way, if you got some issues with the application on the phone, but not on desktop. See selected answer https://stackoverflow.com/questions/42253794/androidinstall-task-causes-a-no-connected-devices-error

## What need to be working on?

* Generate an application for Iphone. Iphone app generation works for this project, but I haven't tested it yet because I focusing on Android at the moment. 
* Search for bugs. If you find any...please open an issue or a pull request. 
* Scale down dependencies inside the build.gradle file, and only use the most necessary for training the deep neural network
* Design and correct dimensions of components

## How is the project organized?
I have always like clean god written code and pedagogy explanations. So I'm going to give you an introduction what every file do. I like to keep files as short as possible. Around 250-300 lines per each java file is a suitable java file. 

* DrawerManager.java -> Handles the menu slide to the left
* Main.java -> Handles the import of new JavaFX pages
* DL4JData.java -> Handles everything that has to do with CSV handling for DL4J
* DL4JModel.java -> Hnaldes everything that has to do with the model (save, load, generate etc.)
* DL4JSerializableConfiguration.java -> Handles saving and loading layers and global config to .ser files
* DL4JThread.java -> Handles training and using the text area and progress bar inside the TrainEvalGeneratePresenter.java file
* Dialogs.java -> Handles everything that has to do with pop-up dialogs
* FileHandler.java -> Handles file system, write files, read files and create files
* SimpleDependencyInjection.java -> Create a static object of DL4JModel.java so we can have access to DL4JModel everywhere
* ConfigurationsPresenter.java -> Handles GUI view for configuration
* DataPresenter.java -> Handles the GUI view for CSV import
* ModelsPresenter.java -> Handles the GUI view for model creation and delete/save
* TrainEvalGeneratePresenter.java -> Handles the GUI view for train, eval and generate C-code

Every file inside se.danielmartensson.views package that contains the word "View" inside its name is only for importing the GUI inside Main.java file. These files never changes.


## Tutorials - If you want to change inside the code
* Tutorials -> Add seed, regularization coefficient, learning rate, momentum
* Tutorials -> Add new updater
* Tutorials -> Add new layer
* Tutorials -> Add inputs and outputs
* Tutorials -> Add new functionality to layers
